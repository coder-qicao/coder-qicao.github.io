1:"$Sreact.fragment"
2:I[3719,["17","static/chunks/17-9c04c9413a9f9f1f.js","874","static/chunks/874-6cc630662f3664af.js","862","static/chunks/862-15038af301665bb3.js","177","static/chunks/app/layout-a2d7e4275da50bac.js"],"ThemeProvider"]
3:I[768,["17","static/chunks/17-9c04c9413a9f9f1f.js","874","static/chunks/874-6cc630662f3664af.js","862","static/chunks/862-15038af301665bb3.js","177","static/chunks/app/layout-a2d7e4275da50bac.js"],"default"]
4:I[7555,[],""]
5:I[1295,[],""]
6:I[2548,["17","static/chunks/17-9c04c9413a9f9f1f.js","874","static/chunks/874-6cc630662f3664af.js","862","static/chunks/862-15038af301665bb3.js","177","static/chunks/app/layout-a2d7e4275da50bac.js"],"default"]
7:I[7437,["17","static/chunks/17-9c04c9413a9f9f1f.js","178","static/chunks/178-595a94b9af1e67b5.js","874","static/chunks/874-6cc630662f3664af.js","588","static/chunks/588-d4a3dd10f217f95c.js","974","static/chunks/app/page-9f21f91e881e66c3.js"],"default"]
8:I[9507,["17","static/chunks/17-9c04c9413a9f9f1f.js","178","static/chunks/178-595a94b9af1e67b5.js","874","static/chunks/874-6cc630662f3664af.js","588","static/chunks/588-d4a3dd10f217f95c.js","974","static/chunks/app/page-9f21f91e881e66c3.js"],"default"]
9:I[5218,["17","static/chunks/17-9c04c9413a9f9f1f.js","178","static/chunks/178-595a94b9af1e67b5.js","874","static/chunks/874-6cc630662f3664af.js","588","static/chunks/588-d4a3dd10f217f95c.js","974","static/chunks/app/page-9f21f91e881e66c3.js"],"default"]
10:I[1990,["17","static/chunks/17-9c04c9413a9f9f1f.js","178","static/chunks/178-595a94b9af1e67b5.js","874","static/chunks/874-6cc630662f3664af.js","588","static/chunks/588-d4a3dd10f217f95c.js","974","static/chunks/app/page-9f21f91e881e66c3.js"],"default"]
11:I[9665,[],"MetadataBoundary"]
13:I[9665,[],"OutletBoundary"]
16:I[4911,[],"AsyncMetadataOutlet"]
18:I[9665,[],"ViewportBoundary"]
1a:I[6614,[],""]
:HL["/_next/static/css/188ffcee146a758d.css","style"]
a:T4c7,Model routing chooses which language model to use for each query. By sending easy queries to cheaper models and hard queries to stronger ones, it can significantly reduce inference cost while maintaining high accuracy. However, most existing routers treat this as a fixed choice among a small set of models, which makes them hard to adapt to new models or changing budget constraints. In this paper, we propose SCOPE (Scalable and Controllable Outcome Performance Estimator), a routing framework that goes beyond model selection by predicting their cost and performance. Trained with reinforcement learning, SCOPE makes reasoning-based predictions by retrieving how models behave on similar problems, rather than relying on fixed model names, enabling it to work with new, unseen models. Moreover, by explicitly predicting how accurate and how expensive a model will be, it turns routing into a dynamic decision problem, allowing users to easily control the trade-off between accuracy and cost. Experiments show that SCOPE is more than just a cost-saving tool. It flexibly adapts to user needs: it can boost accuracy by up to 25.7% when performance is the priority, or cut costs by up to 95.1% when efficiency matters most.b:T64d,@article{cao2026scope,
  title = {Models Under SCOPE: Scalable and Controllable Routing via Pre-hoc Reasoning},
  author = {Qi Cao and Shuhao Zhang and Ruizhe Zhou and Ruiyi Zhang and Peijia Qin and Pengtao Xie},
  year = {2026},
  month = {jan},
  journal = {Arxiv Preprint},
  doi = {https://www.arxiv.org/abs/2601.22323},
  urldate = {2026-01-29},
  langid = {english},
  abstract = {Model routing chooses which language model to use for each query. By sending easy queries to cheaper models and hard queries to stronger ones, it can significantly reduce inference cost while maintaining high accuracy. However, most existing routers treat this as a fixed choice among a small set of models, which makes them hard to adapt to new models or changing budget constraints. In this paper, we propose SCOPE (Scalable and Controllable Outcome Performance Estimator), a routing framework that goes beyond model selection by predicting their cost and performance. Trained with reinforcement learning, SCOPE makes reasoning-based predictions by retrieving how models behave on similar problems, rather than relying on fixed model names, enabling it to work with new, unseen models. Moreover, by explicitly predicting how accurate and how expensive a model will be, it turns routing into a dynamic decision problem, allowing users to easily control the trade-off between accuracy and cost. Experiments show that SCOPE is more than just a cost-saving tool. It flexibly adapts to user needs: it can boost accuracy by up to 25.7% when performance is the priority, or cut costs by up to 95.1% when efficiency matters most.}
}c:T762,Reasoning has substantially improved the performance of large language models (LLMs) on complicated tasks. Central to the current reasoning studies, Process Reward Models (PRMs) offer a fine-grained evaluation of intermediate reasoning steps and guide the reasoning process. However, extending PRMs to multimodal large language models (MLLMs) introduces challenges. Since multimodal reasoning covers a wider range of tasks compared to text-only scenarios, the resulting distribution shift from the training to testing sets is more severe, leading to greater generalization difficulty. Training a reliable multimodal PRM, therefore, demands large and diverse datasets to ensure sufficient coverage. However, current multimodal reasoning datasets suffer from a marked quality imbalance, which degrades PRM performance and highlights the need for an effective data selection strategy. To address the issues, we introduce DreamPRM, a domain-reweighted training framework for multimodal PRMs which employs bi-level optimization. In the lower-level optimization, DreamPRM performs fine-tuning on multiple datasets with domain weights, allowing the PRM to prioritize high-quality reasoning signals and alleviating the impact of dataset quality imbalance. In the upper-level optimization, the PRM is evaluated on a separate meta-learning dataset; this feedback updates the domain weights through an aggregation loss function, thereby improving the generalization capability of trained PRM. Extensive experiments on multiple multimodal reasoning benchmarks covering both mathematical and general reasoning show that test-time scaling with DreamPRM consistently improves the performance of state-of-the-art MLLMs. Further comparisons reveal that DreamPRM's domain-reweighting strategy surpasses other data selection methods and yields higher accuracy gains than existing test-time scaling approaches.d:T92d,@inproceedings{cao2025dreamprm,
  title = {DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning},
  author = {Qi Cao and Ruiyi Wang and Ruiyi Zhang and Sai Ashish Somayajula and Pengtao Xie},
  year = {2025},
  month = {may},
  booktitle = {The Thirty-Ninth Annual Conference on Neural Information Processing Systems (NeurIPS)},
  doi = {https://arxiv.org/abs/2505.20241},
  urldate = {2025-11-04},
  langid = {english},
  abstract = {Reasoning has substantially improved the performance of large language models (LLMs) on complicated tasks. Central to the current reasoning studies, Process Reward Models (PRMs) offer a fine-grained evaluation of intermediate reasoning steps and guide the reasoning process. However, extending PRMs to multimodal large language models (MLLMs) introduces challenges. Since multimodal reasoning covers a wider range of tasks compared to text-only scenarios, the resulting distribution shift from the training to testing sets is more severe, leading to greater generalization difficulty. Training a reliable multimodal PRM, therefore, demands large and diverse datasets to ensure sufficient coverage. However, current multimodal reasoning datasets suffer from a marked quality imbalance, which degrades PRM performance and highlights the need for an effective data selection strategy. To address the issues, we introduce DreamPRM, a domain-reweighted training framework for multimodal PRMs which employs bi-level optimization. In the lower-level optimization, DreamPRM performs fine-tuning on multiple datasets with domain weights, allowing the PRM to prioritize high-quality reasoning signals and alleviating the impact of dataset quality imbalance. In the upper-level optimization, the PRM is evaluated on a separate meta-learning dataset; this feedback updates the domain weights through an aggregation loss function, thereby improving the generalization capability of trained PRM. Extensive experiments on multiple multimodal reasoning benchmarks covering both mathematical and general reasoning show that test-time scaling with DreamPRM consistently improves the performance of state-of-the-art MLLMs. Further comparisons reveal that DreamPRM's domain-reweighting strategy surpasses other data selection methods and yields higher accuracy gains than existing test-time scaling approaches.}
}e:T7be,Pansharpening refers to fusing a low-resolution multispectral image (LRMS) and a high-resolution panchromatic (PAN) image to generate a high-resolution multispectral image (HRMS). Traditional pansharpening methods use a single pair of LRMS and PAN to generate HRMS at full resolution, but they fail to generate high-quality fused products due to the assumption of a (often inaccurate) linear relationship between the fused products. Convolutional neural network methods, i.e., supervised and unsupervised learning approaches, can model any arbitrary non-linear relationship among data, but performing even worse than traditional methods when testing data are not consistent with training data. Moreover, supervised methods rely on simulating reduced resolution data for training causing information loss at full resolution. Unsupervised pansharpening suffers from distortion due to the lack of reference images and inaccuracy in the estimation of the degradation process. In this paper, we propose a zero-shot semi-supervised method for pansharpening (ZS-Pan), which only requires a single pair of PAN/LRMS images for training and testing networks combining both the pros of supervised and unsupervised methods. Facing with challenges of limited training data and no reference images, the ZS-Pan framework is built with a two-phase three-component model, i.e., the reduced resolution supervised pre-training (RSP), the spatial degradation establishment (SDE), and the full resolution unsupervised generation (FUG) stages. Specifically, a special parameter initialization technique, a data augmentation strategy, and a non-linear degradation network are proposed to improve the representation ability of the network. In our experiments, we evaluate the performance of the proposed framework on different datasets using some state-of-the-art (SOTA) pansharpening approaches for comparison. Results show that our ZS-Pan outperforms these SOTA methods, both visually and quantitatively.f:T9a9,@article{cao2024zspan,
  title = {Zero-shot Semi-supervised Learning for Pansharpening},
  author = {Qi Cao and Liang-Jian Deng and Wu Wang and Junming Hou and Gemine Vivone},
  year = {2024},
  month = {jan},
  journal = {Information Fusion},
  doi = {https://www.sciencedirect.com/science/article/pii/S1566253523003172?casa_token=UoG5K9i4aJcAAAAA:d3EaM7LaU-RuamWNhH9g0IkFl_MOGsxi46uNlffI6a4JoWw8NkYF4DKk_UtCLUSYjASQWXQIUg},
  urldate = {2024-01-01},
  langid = {english},
  abstract = {Pansharpening refers to fusing a low-resolution multispectral image (LRMS) and a high-resolution panchromatic (PAN) image to generate a high-resolution multispectral image (HRMS). Traditional pansharpening methods use a single pair of LRMS and PAN to generate HRMS at full resolution, but they fail to generate high-quality fused products due to the assumption of a (often inaccurate) linear relationship between the fused products. Convolutional neural network methods, i.e., supervised and unsupervised learning approaches, can model any arbitrary non-linear relationship among data, but performing even worse than traditional methods when testing data are not consistent with training data. Moreover, supervised methods rely on simulating reduced resolution data for training causing information loss at full resolution. Unsupervised pansharpening suffers from distortion due to the lack of reference images and inaccuracy in the estimation of the degradation process. In this paper, we propose a zero-shot semi-supervised method for pansharpening (ZS-Pan), which only requires a single pair of PAN/LRMS images for training and testing networks combining both the pros of supervised and unsupervised methods. Facing with challenges of limited training data and no reference images, the ZS-Pan framework is built with a two-phase three-component model, i.e., the reduced resolution supervised pre-training (RSP), the spatial degradation establishment (SDE), and the full resolution unsupervised generation (FUG) stages. Specifically, a special parameter initialization technique, a data augmentation strategy, and a non-linear degradation network are proposed to improve the representation ability of the network. In our experiments, we evaluate the performance of the proposed framework on different datasets using some state-of-the-art (SOTA) pansharpening approaches for comparison. Results show that our ZS-Pan outperforms these SOTA methods, both visually and quantitatively.}
}0:{"P":null,"b":"YbSjjBiBTJ1PK7y8-5g5f","p":"","c":["",""],"i":false,"f":[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/188ffcee146a758d.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","className":"scroll-smooth","suppressHydrationWarning":true,"children":[["$","head",null,{"children":[["$","link",null,{"rel":"icon","href":"/favicon.svg","type":"image/svg+xml"}],["$","link",null,{"rel":"dns-prefetch","href":"https://google-fonts.jialeliu.com"}],["$","link",null,{"rel":"preconnect","href":"https://google-fonts.jialeliu.com","crossOrigin":""}],["$","link",null,{"rel":"preload","as":"style","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap"}],["$","link",null,{"rel":"stylesheet","id":"gfonts-css","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap","media":"print"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              (function(){\n                var l = document.getElementById('gfonts-css');\n                if (!l) return;\n                if (l.media !== 'all') {\n                  l.addEventListener('load', function(){ try { l.media = 'all'; } catch(e){} });\n                }\n              })();\n            "}}],["$","noscript",null,{"children":["$","link",null,{"rel":"stylesheet","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap"}]}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              try {\n                const theme = localStorage.getItem('theme-storage');\n                const parsed = theme ? JSON.parse(theme) : null;\n                const setting = parsed?.state?.theme || 'system';\n                const prefersDark = typeof window !== 'undefined' && window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));\n                var root = document.documentElement;\n                root.classList.add(effective);\n                root.setAttribute('data-theme', effective);\n              } catch (e) {\n                var root = document.documentElement;\n                root.classList.add('light');\n                root.setAttribute('data-theme', 'light');\n              }\n            "}}]]}],["$","body",null,{"className":"font-sans antialiased","children":["$","$L2",null,{"children":[["$","$L3",null,{"items":[{"title":"About","type":"page","target":"about","href":"/"},{"title":"Publications","type":"page","target":"publications","href":"/publications"},{"title":"Misc","type":"page","target":"misc","href":"/misc"}],"siteTitle":"Qi Cao","enableOnePageMode":false}],["$","main",null,{"className":"min-h-screen pt-16 lg:pt-20","children":["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","$L6",null,{"lastUpdated":"Jan 30, 2026"}]]}]}]]}]]}],{"children":["__PAGE__",["$","$1","c",{"children":[["$","div",null,{"className":"max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-8 bg-background min-h-screen","children":["$","div",null,{"className":"grid grid-cols-1 lg:grid-cols-3 gap-12","children":[["$","div",null,{"className":"lg:col-span-1","children":["$","$L7",null,{"author":{"name":"Qi Cao","title":"PhD Student","institution":"University of California, San Diego","avatar":"/bio.jpg"},"social":{"email":"q9cao@ucsd.edu","location":"La Jolla, CA","location_url":"https://maps.google.com","location_details":["3195 Voigt Dr,","La Jolla, CA 92093, US"],"google_scholar":"https://scholar.google.com/citations?user=46U_bhgAAAAJ&hl=en","github":"https://github.com/coder-qicao","linkedin":"https://www.linkedin.com/in/qi-cao-86a81b32a/"},"features":{"enable_likes":true,"enable_one_page_mode":false},"researchInterests":["LLM Reasoning","Machine Learning","Reinforcement Learning"]}]}],["$","div",null,{"className":"lg:col-span-2 space-y-8","children":[["$","section","about",{"id":"about","className":"scroll-mt-24 space-y-8","children":[[["$","$L8","about",{"content":"I am Qi Cao, a 2nd-year Ph.D. student in the Department of Electrical and Computer Engineering at the University of California, San Diego, advised by Prof. [Pengtao Xie](https://pengtaoxie.github.io/).\n\nPreviously, I received my B.S. in Mathematics and Physics Class from the Yingcai Honors School at the University of Electronic Science and Technology of China, where I was fortunate to be advised by Prof. [Liangjian Deng](https://liangjiandeng.github.io/index.html).\n\nMy current research focuses on large language model (LLM) reasoning and building LLM-based reasoning systems.","title":"About"}],["$","$L9","featured_publications",{"publications":[{"id":"cao2026scope","title":"Models Under SCOPE: Scalable and Controllable Routing via Pre-hoc Reasoning","authors":[{"name":"Qi Cao","isHighlighted":true,"isCorresponding":true,"isCoAuthor":false},{"name":"Shuhao Zhang","isHighlighted":false,"isCorresponding":true,"isCoAuthor":false},{"name":"Ruizhe Zhou","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Ruiyi Zhang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Peijia Qin","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Pengtao Xie","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2026,"month":"1","type":"journal","status":"published","tags":["Model Routing","LLM Reasoning","Reinforcement Learning","Retrieval Augmentation"],"keywords":"$0:f:0:1:2:children:1:props:children:0:props:children:props:children:1:props:children:0:props:children:0:1:props:publications:0:tags","researchArea":"machine-learning","journal":"Arxiv Preprint","conference":"","doi":"https://www.arxiv.org/abs/2601.22323","code":"https://github.com/Sullivan07043/SCOPE-Router","abstract":"$a","description":"SCOPE, a model routing framework that predicts how accurate and how expensive each model will be before running it, allowing users to control cost-accuracy trade-offs and naturally handle new models.","selected":true,"bibtex":"$b"},{"id":"cao2025dreamprm","title":"DreamPRM: Domain-Reweighted Process Reward Model for Multimodal Reasoning","authors":[{"name":"Qi Cao","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Ruiyi Wang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Ruiyi Zhang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Sai Ashish Somayajula","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Pengtao Xie","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2025,"month":"5","type":"conference","status":"published","tags":["Process Reward Model","LLM Reasoning","Bi-level Optimization"],"keywords":"$0:f:0:1:2:children:1:props:children:0:props:children:props:children:1:props:children:0:props:children:0:1:props:publications:1:tags","researchArea":"machine-learning","journal":"","conference":"The Thirty-Ninth Annual Conference on Neural Information Processing Systems (NeurIPS)","doi":"https://arxiv.org/abs/2505.20241","code":"https://github.com/coder-qicao/DreamPRM","abstract":"$c","description":"A multimodal Process Reward Model (PRM) trained with domain-reweighting. Top 1 method on MathVista, MMMU & R-Bench-V.","selected":true,"awards":["Spotlight @ Multimodal Algorithmic Reasoning Workshop"],"bibtex":"$d"},{"id":"cao2024zspan","title":"Zero-shot Semi-supervised Learning for Pansharpening","authors":[{"name":"Qi Cao","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Liang-Jian Deng","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Wu Wang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Junming Hou","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Gemine Vivone","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2024,"month":"1","type":"journal","status":"published","tags":["Pansharpening","Zero-shot Learning","Semi-supervised Learning"],"keywords":"$0:f:0:1:2:children:1:props:children:0:props:children:props:children:1:props:children:0:props:children:0:1:props:publications:2:tags","researchArea":"machine-learning","journal":"Information Fusion","conference":"","doi":"https://www.sciencedirect.com/science/article/pii/S1566253523003172?casa_token=UoG5K9i4aJcAAAAA:d3EaM7LaU-RuamWNhH9g0IkFl_MOGsxi46uNlffI6a4JoWw8NkYF4DKk_UtCLUSYjASQWXQIUg","code":"https://github.com/coder-qicao/ZS-Pan","abstract":"$e","description":"Zero-shot pansharpening (ZS-Pan) only requires a single pair of PAN/LRMS images. Any pansharpening network can take the ZS-Pan as a plug-and-play module. A two-phase three-component semi-supervised model is designed for ZS-Pan.","selected":true,"bibtex":"$f"}],"title":"Selected Publications","enableOnePageMode":false}],["$","$L10","news",{"items":[{"date":"2026-06","content":"Stating my internship at Meta."},{"date":"2024-09","content":"Starting my PhD at UCSD."}],"title":"News"}]],false,false,false,false]}]]}]]}]}],["$","$L11",null,{"children":"$L12"}],null,["$","$L13",null,{"children":["$L14","$L15",["$","$L16",null,{"promise":"$@17"}]]}]]}],{},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","U2nZ5ID8CXQsYAX7jvAe7",{"children":[["$","$L18",null,{"children":"$L19"}],null]}],null]}],false]],"m":"$undefined","G":["$1a","$undefined"],"s":false,"S":true}
1b:"$Sreact.suspense"
1c:I[4911,[],"AsyncMetadata"]
12:["$","$1b",null,{"fallback":null,"children":["$","$L1c",null,{"promise":"$@1d"}]}]
15:null
19:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
14:null
1d:{"metadata":[["$","title","0",{"children":"Qi Cao"}],["$","meta","1",{"name":"description","content":"PhD student at the University of California, San Diego."}],["$","meta","2",{"name":"author","content":"Qi Cao"}],["$","meta","3",{"name":"keywords","content":"Qi Cao,PhD,Research,University of California, San Diego"}],["$","meta","4",{"name":"creator","content":"Qi Cao"}],["$","meta","5",{"name":"publisher","content":"Qi Cao"}],["$","meta","6",{"property":"og:title","content":"Qi Cao"}],["$","meta","7",{"property":"og:description","content":"PhD student at the University of California, San Diego."}],["$","meta","8",{"property":"og:site_name","content":"Qi Cao's Academic Website"}],["$","meta","9",{"property":"og:locale","content":"en_US"}],["$","meta","10",{"property":"og:type","content":"website"}],["$","meta","11",{"name":"twitter:card","content":"summary"}],["$","meta","12",{"name":"twitter:title","content":"Qi Cao"}],["$","meta","13",{"name":"twitter:description","content":"PhD student at the University of California, San Diego."}],["$","link","14",{"rel":"icon","href":"/favicon.svg"}]],"error":null,"digest":"$undefined"}
17:{"metadata":"$1d:metadata","error":null,"digest":"$undefined"}
